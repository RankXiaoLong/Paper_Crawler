# 2011

## TOC

- [2011-02](#2011-02)
- [2011-03](#2011-03)
- [2011-04](#2011-04)
- [2011-05](#2011-05)
- [2011-06](#2011-06)
- [2011-07](#2011-07)
- [2011-08](#2011-08)
- [2011-09](#2011-09)
- [2011-10](#2011-10)
- [2011-11](#2011-11)
- [2011-12](#2011-12)

## 2011-02

<details>

<summary>2011-02-10 12:46:51 - Estimating conditional quantiles with the help of the pinball loss</summary>

- *Ingo Steinwart, Andreas Christmann*

- `1102.2101v1` - [abs](http://arxiv.org/abs/1102.2101v1) - [pdf](http://arxiv.org/pdf/1102.2101v1)

> The so-called pinball loss for estimating conditional quantiles is a well-known tool in both statistics and machine learning. So far, however, only little work has been done to quantify the efficiency of this tool for nonparametric approaches. We fill this gap by establishing inequalities that describe how close approximate pinball risk minimizers are to the corresponding conditional quantile. These inequalities, which hold under mild assumptions on the data-generating distribution, are then used to establish so-called variance bounds, which recently turned out to play an important role in the statistical analysis of (regularized) empirical risk minimization approaches. Finally, we use both types of inequalities to establish an oracle inequality for support vector machines that use the pinball loss. The resulting learning rates are min--max optimal under some standard regularity assumptions on the conditional quantile.

</details>


## 2011-03

<details>

<summary>2011-03-08 13:28:31 - New efficient estimation and variable selection methods for semiparametric varying-coefficient partially linear models</summary>

- *Bo Kai, Runze Li, Hui Zou*

- `1103.1525v1` - [abs](http://arxiv.org/abs/1103.1525v1) - [pdf](http://arxiv.org/pdf/1103.1525v1)

> The complexity of semiparametric models poses new challenges to statistical inference and model selection that frequently arise from real applications. In this work, we propose new estimation and variable selection procedures for the semiparametric varying-coefficient partially linear model. We first study quantile regression estimates for the nonparametric varying-coefficient functions and the parametric regression coefficients. To achieve nice efficiency properties, we further develop a semiparametric composite quantile regression procedure. We establish the asymptotic normality of proposed estimators for both the parametric and nonparametric parts and show that the estimators achieve the best convergence rate. Moreover, we show that the proposed method is much more efficient than the least-squares-based method for many non-normal errors and that it only loses a small amount of efficiency for normal errors. In addition, it is shown that the loss in efficiency is at most 11.1% for estimating varying coefficient functions and is no greater than 13.6% for estimating parametric components. To achieve sparsity with high-dimensional covariates, we propose adaptive penalization methods for variable selection in the semiparametric varying-coefficient partially linear model and prove that the methods possess the oracle property. Extensive Monte Carlo simulation studies are conducted to examine the finite-sample performance of the proposed procedures. Finally, we apply the new methods to analyze the plasma beta-carotene level data.

</details>

<details>

<summary>2011-03-14 10:09:33 - Type I error rate control for testing many hypotheses: a survey with proofs</summary>

- *Etienne Roquain*

- `1012.4078v2` - [abs](http://arxiv.org/abs/1012.4078v2) - [pdf](http://arxiv.org/pdf/1012.4078v2)

> This paper presents a survey on some recent advances for the type I error rate control in multiple testing methodology. We consider the problem of controlling the $k$-family-wise error rate (kFWER, probability to make $k$ false discoveries or more) and the false discovery proportion (FDP, proportion of false discoveries among the discoveries). The FDP is controlled either via its expectation, which is the so-called false discovery rate (FDR), or via its upper-tail distribution function. We aim at deriving general and unified results together with concise and simple mathematical proofs. Furthermore, while this paper is mainly meant to be a survey paper, some new contributions for controlling the kFWER and the upper-tail distribution function of the FDP are provided. In particular, we derive a new procedure based on the quantiles of the binomial distribution that controls the FDP under independence.

</details>

<details>

<summary>2011-03-14 19:42:53 - Bahadur Representation for U-Quantiles of Dependent Data</summary>

- *Martin Wendler*

- `1004.2581v3` - [abs](http://arxiv.org/abs/1004.2581v3) - [pdf](http://arxiv.org/pdf/1004.2581v3)

> U-quantiles are applied in robust statistics, like the Hodges-Lehmann estimator of location for example. They have been analyzed in the case of independent random variables with the help of a generalized Bahadur representation. Our main aim is to extend these results to U-quantiles of strongly mixing random variables and functionals of absolutely regular sequences. We obtain the central limit theorem and the law of the iterated logarithm for U-quantiles as straightforward corollaries. Furthermore, we improve the existing result for sample quantiles of mixing data.

</details>

<details>

<summary>2011-03-25 09:12:03 - Group Lasso for high dimensional sparse quantile regression models</summary>

- *Kengo Kato*

- `1103.1458v2` - [abs](http://arxiv.org/abs/1103.1458v2) - [pdf](http://arxiv.org/pdf/1103.1458v2)

> This paper studies the statistical properties of the group Lasso estimator for high dimensional sparse quantile regression models where the number of explanatory variables (or the number of groups of explanatory variables) is possibly much larger than the sample size while the number of variables in "active" groups is sufficiently small. We establish a non-asymptotic bound on the $\ell_{2}$-estimation error of the estimator. This bound explains situations under which the group Lasso estimator is potentially superior/inferior to the $\ell_{1}$-penalized quantile regression estimator in terms of the estimation error. We also propose a data-dependent choice of the tuning parameter to make the method more practical, by extending the original proposal of Belloni and Chernozhukov (2011) for the $\ell_{1}$-penalized quantile regression estimator. As an application, we analyze high dimensional additive quantile regression models. We show that under a set of suitable regularity conditions, the group Lasso estimator can attain the convergence rate arbitrarily close to the oracle rate. Finally, we conduct simulations experiments to examine our theoretical results.

</details>

<details>

<summary>2011-03-29 10:02:33 - Probability boxes on totally preordered spaces for multivariate modelling</summary>

- *Matthias C. M. Troffaes, Sebastien Destercke*

- `1103.1805v2` - [abs](http://arxiv.org/abs/1103.1805v2) - [pdf](http://arxiv.org/pdf/1103.1805v2)

> A pair of lower and upper cumulative distribution functions, also called probability box or p-box, is among the most popular models used in imprecise probability theory. They arise naturally in expert elicitation, for instance in cases where bounds are specified on the quantiles of a random variable, or when quantiles are specified only at a finite number of points. Many practical and formal results concerning p-boxes already exist in the literature. In this paper, we provide new efficient tools to construct multivariate p-boxes and develop algorithms to draw inferences from them. For this purpose, we formalise and extend the theory of p-boxes using Walley's behavioural theory of imprecise probabilities, and heavily rely on its notion of natural extension and existing results about independence modeling. In particular, we allow p-boxes to be defined on arbitrary totally preordered spaces, hence thereby also admitting multivariate p-boxes via probability bounds over any collection of nested sets. We focus on the cases of independence (using the factorization property), and of unknown dependence (using the Fr\'echet bounds), and we show that our approach extends the probabilistic arithmetic of Williamson and Downs. Two design problems---a damped oscillator, and a river dike---demonstrate the practical feasibility of our results.

</details>

<details>

<summary>2011-03-31 14:55:30 - Bias-reduced extreme quantiles estimators of Weibull-tail distributions</summary>

- *Jean Diebolt, Laurent Gardes, Stéphane Girard, Armelle Guillou*

- `1103.6204v1` - [abs](http://arxiv.org/abs/1103.6204v1) - [pdf](http://arxiv.org/pdf/1103.6204v1)

> In this paper, we consider the problem of estimating an extreme quantile of a Weibull tail-distribution. The new extreme quantile estimator has a reduced bias compared to the more classical ones proposed in the literature. It is based on an exponential regression model that was introduced in Diebolt et al. (2008). The asymptotic normality of the extreme quantile estimator is established. We also introduce an adaptive selection procedure to determine the number of upper order statistics to be used. A simulation study as well as an application to a real data set are provided in order to prove the efficiency of the above mentioned methods.

</details>

<details>

<summary>2011-03-31 15:36:20 - Quasi-conjugate Bayes estimates for GPD parameters and application to heavy tails modelling</summary>

- *Jean Diebolt, Mhamed El-Aroui, Myriam Garrido, Stéphane Girard*

- `1103.6216v1` - [abs](http://arxiv.org/abs/1103.6216v1) - [pdf](http://arxiv.org/pdf/1103.6216v1)

> We present a quasi-conjugate Bayes approach for estimating Generalized Pareto Distribution (GPD) parameters, distribution tails and extreme quantiles within the Peaks-Over-Threshold framework. Damsleth conjugate Bayes structure on Gamma distributions is transfered to GPD. Posterior estimates are then computed by Gibbs samplers with Hastings-Metropolis steps. Accurate Bayes credibility intervals are also defined, they provide assessment of the quality of the extreme events estimates. An empirical Bayesian method is used in this work, but the suggested approach could incorporate prior information. It is shown that the obtained quasi-conjugate Bayes estimators compare well with the GPD standard estimators when simulated and real data sets are studied.

</details>


## 2011-04

<details>

<summary>2011-04-01 13:27:57 - Functional nonparametric estimation of conditional extreme quantiles</summary>

- *L. Gardes, S. Girard, A. Lekina*

- `1104.0166v1` - [abs](http://arxiv.org/abs/1104.0166v1) - [pdf](http://arxiv.org/pdf/1104.0166v1)

> We address the estimation of quantiles from heavy-tailed distributions when functional covariate information is available and in the case where the order of the quantile converges to one as the sample size increases. Such "extreme" quantiles can be located in the range of the data or near and even beyond the boundary of the sample, depending on the convergence rate of their order to one. Nonparametric estimators of these functional extreme quantiles are introduced, their asymptotic distributions are established and their finite sample behavior is investigated.

</details>

<details>

<summary>2011-04-05 08:19:20 - Comparison of Weibull tail-coefficient estimators</summary>

- *Laurent Gardes, Stéphane Girard*

- `1104.0764v1` - [abs](http://arxiv.org/abs/1104.0764v1) - [pdf](http://arxiv.org/pdf/1104.0764v1)

> We address the problem of estimating the Weibull tail-coefficient which is the regular variation exponent of the inverse failure rate function. We propose a family of estimators of this coefficient and an associate extreme quantile estimator. Their asymptotic normality are established and their asymptotic mean-square errors are compared. The results are illustrated on some finite sample situations.

</details>

<details>

<summary>2011-04-22 06:47:28 - Limit theorems for functions of marginal quantiles</summary>

- *G. Jogesh Babu, Zhidong Bai, Kwok Pui Choi, Vasudevan Mangalam*

- `1104.4396v1` - [abs](http://arxiv.org/abs/1104.4396v1) - [pdf](http://arxiv.org/pdf/1104.4396v1)

> Multivariate distributions are explored using the joint distributions of marginal sample quantiles. Limit theory for the mean of a function of order statistics is presented. The results include a multivariate central limit theorem and a strong law of large numbers. A result similar to Bahadur's representation of quantiles is established for the mean of a function of the marginal quantiles. In particular, it is shown that \[\sqrt{n}\Biggl(\frac{1}{n}\sum_{i=1}^n\phi\bigl(X_{n:i}^{(1)},...,X_{n:i}^{(d)}\bigr)-\bar{\gamma}\Biggr)=\frac{1}{\sqrt{n}}\sum_{i=1}^nZ_{n,i}+\mathrm{o}_P(1)\] as $n\rightarrow\infty$, where $\bar{\gamma}$ is a constant and $Z_{n,i}$ are i.i.d. random variables for each $n$. This leads to the central limit theorem. Weak convergence to a Gaussian process using equicontinuity of functions is indicated. The results are established under very general conditions. These conditions are shown to be satisfied in many commonly occurring situations.

</details>


## 2011-05

<details>

<summary>2011-05-18 07:39:58 - Delta method in large deviations and moderate deviations for estimators</summary>

- *Fuqing Gao, Xingqiu Zhao*

- `1105.3552v1` - [abs](http://arxiv.org/abs/1105.3552v1) - [pdf](http://arxiv.org/pdf/1105.3552v1)

> The delta method is a popular and elementary tool for deriving limiting distributions of transformed statistics, while applications of asymptotic distributions do not allow one to obtain desirable accuracy of approximation for tail probabilities. The large and moderate deviation theory can achieve this goal. Motivated by the delta method in weak convergence, a general delta method in large deviations is proposed. The new method can be widely applied to driving the moderate deviations of estimators and is illustrated by examples including the Wilcoxon statistic, the Kaplan--Meier estimator, the empirical quantile processes and the empirical copula function. We also improve the existing moderate deviations results for $M$-estimators and $L$-statistics by the new method. Some applications of moderate deviations to statistical hypothesis testing are provided.

</details>

<details>

<summary>2011-05-30 11:52:55 - On multivariate quantiles under partial orders</summary>

- *Alexandre Belloni, Robert L. Winkler*

- `0912.5489v3` - [abs](http://arxiv.org/abs/0912.5489v3) - [pdf](http://arxiv.org/pdf/0912.5489v3)

> This paper focuses on generalizing quantiles from the ordering point of view. We propose the concept of partial quantiles, which are based on a given partial order. We establish that partial quantiles are equivariant under order-preserving transformations of the data, robust to outliers, characterize the probability distribution if the partial order is sufficiently rich, generalize the concept of efficient frontier, and can measure dispersion from the partial order perspective. We also study several statistical aspects of partial quantiles. We provide estimators, associated rates of convergence, and asymptotic distributions that hold uniformly over a continuum of quantile indices. Furthermore, we provide procedures that can restore monotonicity properties that might have been disturbed by estimation error, establish computational complexity bounds, and point out a concentration of measure phenomenon (the latter under independence and the componentwise natural order). Finally, we illustrate the concepts by discussing several theoretical examples and simulations. Empirical applications to compare intake nutrients within diets, to evaluate the performance of investment funds, and to study the impact of policies on tobacco awareness are also presented to illustrate the concepts and their use.

</details>


## 2011-06

<details>

<summary>2011-06-09 14:15:23 - Classification Loss Function for Parameter Ensembles in Bayesian Hierarchical Models</summary>

- *Cedric E. Ginestet, Nicky G. Best, Sylvia Richardson*

- `1105.6322v2` - [abs](http://arxiv.org/abs/1105.6322v2) - [pdf](http://arxiv.org/pdf/1105.6322v2)

> Parameter ensembles or sets of point estimates constitute one of the cornerstones of modern statistical practice. This is especially the case in Bayesian hierarchical models, where different decision-theoretic frameworks can be deployed to summarize such parameter ensembles. The estimation of these parameter ensembles may thus substantially vary depending on which inferential goals are prioritised by the modeller. In this note, we consider the problem of classifying the elements of a parameter ensemble above or below a given threshold. Two threshold classification losses (TCLs) --weighted and unweighted-- are formulated. The weighted TCL can be used to emphasize the estimation of false positives over false negatives or the converse. We prove that the weighted and unweighted TCLs are optimized by the ensembles of unit-specific posterior quantiles and posterior medians, respectively. In addition, we relate these classification loss functions on parameter ensembles to the concepts of posterior sensitivity and specificity. Finally, we find some relationships between the unweighted TCL and the absolute value loss, which explain why both functions are minimized by posterior medians.

</details>

<details>

<summary>2011-06-25 16:39:24 - The Empirical Edgeworth Expansion for a Studentized Trimmed Mean</summary>

- *Nadezhda Gribkova, Roelof Helmers*

- `1106.2219v2` - [abs](http://arxiv.org/abs/1106.2219v2) - [pdf](http://arxiv.org/pdf/1106.2219v2)

> We establish the validity of the empirical Edgeworth expansion (EE) for a studentized trimmed mean, under the sole condition that the underlying distribution function of the observations satisfies a local smoothness condition near the two quantiles where the trimming occurs. A simple explicit formula for the N^{-1/2} term (correcting for skewness and bias; N being the sample size) of the EE is given. In particular our result supplements previous work by P. Hall and A.R. Padmanabhan, On the bootstrap and the trimmed mean}, J. of Multivariate Analysis, v. 41 (1992), pp. 132-153. and H. Putter and W.R. van Zwet,   Empirical Edgeworth expansions for symmetric statistics, Ann. Statist., v. 26 (1998), pp. 1540-1569. The proof is based on a U-statistic type approximation and also uses a version of Bahadur's representation for sample quantiles.

</details>

<details>

<summary>2011-06-28 09:31:24 - Level sets estimation and Vorob'ev expectation of random compact sets</summary>

- *Philippe Heinrich, Radu Stefan Stoica, Viet Chi Tran*

- `1006.5135v2` - [abs](http://arxiv.org/abs/1006.5135v2) - [pdf](http://arxiv.org/pdf/1006.5135v2)

> The issue of a "mean shape" of a random set $X$ often arises, in particular in image analysis and pattern detection. There is no canonical definition but one possible approach is the so-called Vorob'ev expectation $\E_V(X)$, which is closely linked to quantile sets. In this paper, we propose a consistent and ready to use estimator of $\E_V(X)$ built from independent copies of $X$ with spatial discretization. The control of discretization errors is handled with a mild regularity assumption on the boundary of $X$: a not too large 'box counting' dimension. Some examples are developed and an application to cosmological data is presented.

</details>


## 2011-07

<details>

<summary>2011-07-04 06:19:55 - Expectiles for subordinated Gaussian processes with applications</summary>

- *Jean-François Coeurjolly, Hedi Kortas*

- `1107.0540v1` - [abs](http://arxiv.org/abs/1107.0540v1) - [pdf](http://arxiv.org/pdf/1107.0540v1)

> In this paper, we introduce a new class of estimators of the Hurst exponent of the fractional Brownian motion (fBm) process. These estimators are based on sample expectiles of discrete variations of a sample path of the fBm process. In order to derive the statistical properties of the proposed estimators, we establish asymptotic results for sample expectiles of subordinated stationary Gaussian processes with unit variance and correlation function satisfying $\rho(i)\sim \kappa|i|^{-\alpha}$ ($\kappa\in \RR$) with $\alpha>0$. Via a simulation study, we demonstrate the relevance of the expectile-based estimation method and show that the suggested estimators are more robust to data rounding than their sample quantile-based counterparts.

</details>


## 2011-08

<details>

<summary>2011-08-09 06:34:33 - Percentile rank scores are congruous indicators of relative performance, or aren't they?</summary>

- *Ronald Rousseau*

- `1108.1860v1` - [abs](http://arxiv.org/abs/1108.1860v1) - [pdf](http://arxiv.org/pdf/1108.1860v1)

> Percentile ranks and the I3 indicator were introduced by Bornmann, Leydesdorff, Mutz and Opthof. These two notions are based on the concept of percentiles (or quantiles) for discrete data. As several definitions for these notions exist we propose one that we think is suitable in this context. Next we show that if the notion of relative congruous indicators is carefully defined then percentile rank scores are congruous indicators of relative performance. The I3 indicator is a strictly congruous indicator of absolute performance.

</details>

<details>

<summary>2011-08-12 15:48:26 - Challenging the empirical mean and empirical variance: a deviation study</summary>

- *Olivier Catoni*

- `1009.2048v2` - [abs](http://arxiv.org/abs/1009.2048v2) - [pdf](http://arxiv.org/pdf/1009.2048v2)

> We present new M-estimators of the mean and variance of real valued random variables, based on PAC-Bayes bounds. We analyze the non-asymptotic minimax properties of the deviations of those estimators for sample distributions having either a bounded variance or a bounded variance and a bounded kurtosis. Under those weak hypotheses, allowing for heavy-tailed distributions, we show that the worst case deviations of the empirical mean are suboptimal. We prove indeed that for any confidence level, there is some M-estimator whose deviations are of the same order as the deviations of the empirical mean of a Gaussian statistical sample, even when the statistical sample is instead heavy-tailed. Experiments reveal that these new estimators perform even better than predicted by our bounds, showing deviation quantile functions uniformly lower at all probability levels than the empirical mean for non Gaussian sample distributions as simple as the mixture of two Gaussian measures.

</details>


## 2011-09

<details>

<summary>2011-09-29 14:55:20 - Robust Estimators in Generalized Pareto Models</summary>

- *Peter Ruckdeschel, Nataliya Horbenko*

- `1005.1476v6` - [abs](http://arxiv.org/abs/1005.1476v6) - [pdf](http://arxiv.org/pdf/1005.1476v6)

> This paper deals with optimally-robust parameter estimation in generalized Pareto distributions (GPDs). These arise naturally in many situations where one is interested in the behavior of extreme events as motivated by the Pickands-Balkema-de Haan extreme value theorem (PBHT). The application we have in mind is calculation of the regulatory capital required by Basel II for a bank to cover operational risk. In this context the tail behavior of the underlying distribution is crucial. This is where extreme value theory enters, suggesting to estimate these high quantiles parameterically using, e.g. GPDs. Robust statistics in this context offers procedures bounding the influence of single observations, so provides reliable inference in the presence of moderate deviations from the distributional model assumptions, respectively from the mechanisms underlying the PBHT.

</details>


## 2011-10

<details>

<summary>2011-10-08 14:34:43 - A-Collapsibility of Distribution Dependence and Quantile Regression Coefficients</summary>

- *P. Vellaisamy*

- `0906.5546v4` - [abs](http://arxiv.org/abs/0906.5546v4) - [pdf](http://arxiv.org/pdf/0906.5546v4)

> The Yule-Simpson paradox notes that an association between random variables can be reversed when averaged over a background variable. Cox and Wermuth (2003) introduced the concept of distribution dependence between two random variables X and Y, and developed two dependence conditions, each of which guarantees that reversal cannot occur. Ma, Xie and Geng (2006) studied the collapsibility of distribution dependence over a background variable W, under a rather strong homogeneity condition. Collapsibility ensures the association remains the same for conditional and marginal models, so that Yule-Simpson reversal cannot occur. In this paper, we investigate a more general condition for avoiding effect reversal: A-collapsibility. The conditions of Cox and Wermuth imply A-collapsibility, without assuming homogeneity. In fact, we show that, when W is a binary variable, collapsibility is equivalent to A-collapsibility plus homogeneity, and A-collapsibility is equivalent to the conditions of Cox and Wermuth. Recently, Cox (2007) extended Cochran's result on regression coefficients of conditional and marginal models, to quantile regression coefficients. The conditions of Cox and Wermuth are sufficient for A-collapsibility of quantile regression coefficients. If the conditional distribution of W, given Y = y and X = x, belong to one-dimensional natural exponential family, they are also necessary. Some applications of A-collapsibility include the analysis of a contingency table, linear regression models and quantile regression models.

</details>

<details>

<summary>2011-10-15 19:32:21 - New Entropy Estimator with an Application to Test of Normality</summary>

- *Salim Bouzebda, Issam Elhattab, Amor Keziou, Tewfik Lounis*

- `1110.3436v1` - [abs](http://arxiv.org/abs/1110.3436v1) - [pdf](http://arxiv.org/pdf/1110.3436v1)

> In the present paper we propose a new estimator of entropy based on smooth estimators of quantile density. The consistency and asymptotic distribution of the proposed estimates are obtained. As a consequence, a new test of normality is proposed. A small power comparison is provided. A simulation study for the comparison, in terms of mean squared error, of all estimators under study is performed.

</details>

<details>

<summary>2011-10-27 09:07:17 - Ordinal Risk-Group Classification</summary>

- *Yizhar Toren*

- `1012.5487v4` - [abs](http://arxiv.org/abs/1012.5487v4) - [pdf](http://arxiv.org/pdf/1012.5487v4)

> Most classification methods provide either a prediction of class membership or an assessment of class membership probability. In the case of two-group classification the predicted probability can be described as "risk" of belonging to a "special" class . When the required output is a set of ordinal-risk groups, a discretization of the continuous risk prediction is achieved by two common methods: by constructing a set of models that describe the conditional risk function at specific points (quantile regression) or by dividing the output of an "optimal" classification model into adjacent intervals that correspond to the desired risk groups. By defining a new error measure for the distribution of risk onto intervals we are able to identify lower bounds on the accuracy of these methods, showing sub-optimality both in their distribution of risk and in the efficiency of their resulting partition into intervals. By adding a new form of constraint to the existing maximum likelihood optimization framework and by introducing a penalty function to avoid degenerate solutions, we show how existing methods can be augmented to solve the ordinal risk-group classification problem. We implement our method for logistic regression (LR) and show a numeric example.

</details>


## 2011-11

<details>

<summary>2011-11-18 20:23:12 - On the Pickands stochastic process</summary>

- *Gane Samb Lo, Adja Mbarka Fall*

- `1111.4469v1` - [abs](http://arxiv.org/abs/1111.4469v1) - [pdf](http://arxiv.org/pdf/1111.4469v1)

> We consider the Pickands process {equation*} P_{n}(s)=\log (1/s)^{-1}\log \frac{X_{n-k+1,n}-X_{n-[k/s]+1,n}}{% X_{n-[k/s]+1,n}-X_{n-[k/s^{2}]+1,n}}, {equation*} {equation*} (\frac{k}{n}\leq s^2 \leq 1), {equation*} which is a generalization of the classical Pickands estimate $P_{n}(1/2)$ of the extremal index. We undertake here a purely stochastic process view for the asymptotic theory of that process by using the Cs\"{o}rg\H{o}-Cs\"{o}rg\H{o}-Horv\'{a}th-Mason (1986) \cite{cchm} weighted approximation of the empirical and quantile processes to suitable Brownian bridges. This leads to the uniform convergence of the margins of this process to the extremal index and a complete theory of weak convergence of $P_n$ in $\ell^{\infty}([a,b])$ to some Gaussian process $$\{\mathbb{G},a\leq s \leq b\} $$ for all $[a,b] \subset]0,1[$. This frame greatly simplifies the former results and enable applications based on stochastic processes methods.

</details>

<details>

<summary>2011-11-19 22:29:05 - Empirical Quantile CLTs for Time Dependent Data</summary>

- *James Kuelbs, Joel Zinn*

- `1111.4591v1` - [abs](http://arxiv.org/abs/1111.4591v1) - [pdf](http://arxiv.org/pdf/1111.4591v1)

> We establish empirical quantile process CLTs based on $n$ independent copies of a stochastic process $\{X_t: t \in E\}$ that are uniform in $t \in E$ and quantile levels $\alpha \in I$, where $I$ is a closed sub-interval of $(0,1)$. Typically $E=[0,T]$, or a finite product of such intervals. Also included are CLT's for the empirical process based on $\{I_{X_t \le y} - \rm {Pr}(X_t \le y): t \in E, y \in R \}$ that are uniform in $t \in E, y \in R$. The process $\{X_t: t \in E\}$ may be chosen from a broad collection of Gaussian processes, compound Poisson processes, stationary independent increment stable processes, and martingales.

</details>

<details>

<summary>2011-11-23 07:23:48 - Universality of sample covariance matrices: CLT of the smoothed empirical spectral distribution</summary>

- *Guangming Pan, Qi-Man Shao, Wang Zhou*

- `1111.5420v1` - [abs](http://arxiv.org/abs/1111.5420v1) - [pdf](http://arxiv.org/pdf/1111.5420v1)

> A central limit theorem (CLT) for the smoothed empirical spectral distribution of sample covariance matrices is established. Moreover, the CLTs for the smoothed quantiles of Marcenko and Pastur's law have been also developed.

</details>

<details>

<summary>2011-11-28 12:25:35 - Semiparametric efficiency bounds for seemingly unrelated conditional moment restrictions</summary>

- *Marian Hristache, Valentin Patilea*

- `1111.6428v1` - [abs](http://arxiv.org/abs/1111.6428v1) - [pdf](http://arxiv.org/pdf/1111.6428v1)

> This paper addresses the problem of semiparametric efficiency bounds for conditional moment restriction models with different conditioning variables. We characterize such an efficiency bound, that in general is not explicit, as a limit of explicit efficiency bounds for a decreasing sequence of unconditional (marginal) moment restriction models. An iterative procedure for approximating the efficient score when this is not explicit is provided. Our theoretical results complete and extend existing results in the literature, provide new insight for the theory of semiparametric efficiency bounds literature and open the door to new applications. In particular, we investigate a class of regression-like (mean regression, quantile regression,...) models with missing data.

</details>

<details>

<summary>2011-11-29 17:04:26 - Extended Generalised Pareto Models for Tail Estimation</summary>

- *Ioannis Papastathopoulos, Jonathan A. Tawn*

- `1111.6899v1` - [abs](http://arxiv.org/abs/1111.6899v1) - [pdf](http://arxiv.org/pdf/1111.6899v1)

> The most popular approach in extreme value statistics is the modelling of threshold exceedances using the asymptotically motivated generalised Pareto distribution. This approach involves the selection of a high threshold above which the model fits the data well. Sometimes, few observations of a measurement process might be recorded in applications and so selecting a high quantile of the sample as the threshold leads to almost no exceedances. In this paper we propose extensions of the generalised Pareto distribution that incorporate an additional shape parameter while keeping the tail behaviour unaffected. The inclusion of this parameter offers additional structure for the main body of the distribution, improves the stability of the modified scale, tail index and return level estimates to threshold choice and allows a lower threshold to be selected. We illustrate the benefits of the proposed models with a simulation study and two case studies.

</details>


## 2011-12

<details>

<summary>2011-12-07 19:16:30 - Quantile Mechanics II: Changes of Variables in Monte Carlo methods and GPU-Optimized Normal Quantiles</summary>

- *William T. Shaw, Thomas Luu, Nick Brickman*

- `0901.0638v5` - [abs](http://arxiv.org/abs/0901.0638v5) - [pdf](http://arxiv.org/pdf/0901.0638v5)

> This article presents differential equations and solution methods for the functions of the form $Q(x) = F^{-1}(G(x))$, where $F$ and $G$ are cumulative distribution functions. Such functions allow the direct recycling of Monte Carlo samples from one distribution into samples from another. The method may be developed analytically for certain special cases, and illuminate the idea that it is a more precise form of the traditional Cornish-Fisher expansion. In this manner the model risk of distributional risk may be assessed free of the Monte Carlo noise associated with resampling. Examples are given of equations for converting normal samples to Student t, and converting exponential to hyperbolic, variance gamma and normal. In the case of the normal distribution, the change of variables employed allows the sampling to take place to good accuracy based on a single rational approximation over a very wide range of the sample space. The avoidance of any branching statement is of use in optimal GPU computations as it avoids the effect of {\it warp divergence}, and we give examples of branch-free normal quantiles that offer performance improvements in a GPU environment, while retaining the best precision characteristics of well-known methods. We also offer models based on a low-probability of warp divergence. Comparisons of new and old forms are made on the Nvidia Quadro 4000, GTX 285 and 480, and Tesla C2050 GPUs. We argue that in single-precision mode, the change-of-variables approach offers performance competitive with the fastest existing scheme while substantially improving precision, and that in double-precision mode, this approach offers the most GPU-optimal Gaussian quantile yet, and without compromise on precision for Monte Carlo applications, working twice as fast as the CUDA 4 library function with increased precision.

</details>

<details>

<summary>2011-12-13 22:17:47 - The Dirichlet Process with Large Concentration Parameter</summary>

- *Luai Al Labadi, Mahmoud Zarepour*

- `1109.5261v3` - [abs](http://arxiv.org/abs/1109.5261v3) - [pdf](http://arxiv.org/pdf/1109.5261v3)

> Ferguson's Dirichlet process plays an important role in nonparametric Bayesian inference. Let $P_a$ be the Dirichlet process in $\mathbb{R}$ with a base probability measure $H$ and a concentration parameter $a>0.$ In this paper, we show that $\sqrt {a} \big(P_a((-\infty,t]) -H((-\infty,t])\big)$ converges to a certain Brownian bridge as $a \to \infty.$ We also derive a certain Glivenko-Cantelli theorem for the Dirichlet process. Using the functional delta method, the weak convergence of the quantile process is also obtained. A large concentration parameter occurs when a statistician puts too much emphasize on his/her prior guess. This scenario also happens when the sample size is large and the posterior is used to make inference.

</details>

<details>

<summary>2011-12-14 22:07:09 - Quantile Based Variable Mining : Detection, FDR based Extraction and Interpretation</summary>

- *S. Mukhopadhyay, Emanuel Parzen, S. N. Lahiri*

- `1112.3373v1` - [abs](http://arxiv.org/abs/1112.3373v1) - [pdf](http://arxiv.org/pdf/1112.3373v1)

> This paper outlines a unified framework for high dimensional variable selection for classification problems. Traditional approaches to finding interesting variables mostly utilize only partial information through moments (like mean difference). On the contrary, in this paper we address the question of variable selection in full generality from a distributional point of view. If a variable is not important for classification, then it will have similar distributional aspect under different classes. This simple and straightforward observation motivates us to quantify `How and Why' the distribution of a variable changes over classes through CR-statistic. The second contribution of our paper is to develop and investigate the FDR based thresholding technology from a completely new point of view for adaptive thresholding, which leads to a elegant algorithm called CDfdr. This paper attempts to show how all of these problems of detection, extraction and interpretation for interesting variables can be treated in a unified way under one broad general theme - comparison analysis. It is proposed that a key to accomplishing this unification is to think in terms of the quantile function and the comparison density. We illustrate and demonstrate the power of our methodology using three real data sets.

</details>

<details>

<summary>2011-12-30 02:24:12 - Bayesian Quantile Regression for Single-Index Models</summary>

- *Yuao Hua, Robert B. Gramacy, Heng Lian*

- `1110.0219v2` - [abs](http://arxiv.org/abs/1110.0219v2) - [pdf](http://arxiv.org/pdf/1110.0219v2)

> Using an asymmetric Laplace distribution, which provides a mechanism for Bayesian inference of quantile regression models, we develop a fully Bayesian approach to fitting single-index models in conditional quantile regression. In this work, we use a Gaussian process prior for the unknown nonparametric link function and a Laplace distribution on the index vector, with the latter motivated by the recent popularity of the Bayesian lasso idea. We design a Markov chain Monte Carlo algorithm for posterior inference. Careful consideration of the singularity of the kernel matrix, and tractability of some of the full conditional distributions leads to a partially collapsed approach where the nonparametric link function is integrated out in some of the sampling steps. Our simulations demonstrate the superior performance of the Bayesian method versus the frequentist approach. The method is further illustrated by an application to the hurricane data.

</details>

