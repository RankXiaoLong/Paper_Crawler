# 2004

## TOC

- [2004-03](#2004-03)
- [2004-06](#2004-06)
- [2004-10](#2004-10)
- [2004-11](#2004-11)
- [2004-12](#2004-12)

## 2004-03

<details>

<summary>2004-03-15 16:33:55 - Distribution of Mutual Information from Complete and Incomplete Data</summary>

- *Marcus Hutter, Marco Zaffalon*

- `0403025v1` - [abs](http://arxiv.org/abs/0403025v1) - [pdf](http://arxiv.org/pdf/cs/0403025v1)

> Mutual information is widely used, in a descriptive way, to measure the stochastic dependence of categorical random variables. In order to address questions such as the reliability of the descriptive value, one must consider sample-to-population inferential approaches. This paper deals with the posterior distribution of mutual information, as obtained in a Bayesian framework by a second-order Dirichlet prior distribution. The exact analytical expression for the mean, and analytical approximations for the variance, skewness and kurtosis are derived. These approximations have a guaranteed accuracy level of the order O(1/n^3), where n is the sample size. Leading order approximations for the mean and the variance are derived in the case of incomplete samples. The derived analytical expressions allow the distribution of mutual information to be approximated reliably and quickly. In fact, the derived expressions can be computed with the same order of complexity needed for descriptive mutual information. This makes the distribution of mutual information become a concrete alternative to descriptive mutual information in many applications which would benefit from moving to the inductive side. Some of these prospective applications are discussed, and one of them, namely feature selection, is shown to perform significantly better when inductive mutual information is used.

</details>


## 2004-06

<details>

<summary>2004-06-10 16:36:54 - Suboptimal behaviour of Bayes and MDL in classification under misspecification</summary>

- *Peter Grunwald, John Langford*

- `0406221v1` - [abs](http://arxiv.org/abs/0406221v1) - [pdf](http://arxiv.org/pdf/math/0406221v1)

> We show that forms of Bayesian and MDL inference that are often applied to classification problems can be *inconsistent*. This means there exists a learning problem such that for all amounts of data the generalization errors of the MDL classifier and the Bayes classifier relative to the Bayesian posterior both remain bounded away from the smallest achievable generalization error.

</details>

<details>

<summary>2004-06-23 08:01:45 - Sufficient burn-in for Gibbs samplers for a hierarchical random effects model</summary>

- *Galin L. Jones, James P. Hobert*

- `0406454v1` - [abs](http://arxiv.org/abs/0406454v1) - [pdf](http://arxiv.org/pdf/math/0406454v1)

> We consider Gibbs and block Gibbs samplers for a Bayesian hierarchical version of the one-way random effects model. Drift and minorization conditions are established for the underlying Markov chains. The drift and minorization are used in conjunction with results from J. S. Rosenthal [J. Amer. Statist.   Assoc. 90 (1995) 558-566] and G. O. Roberts and R. L. Tweedie [Stochastic   Process. Appl. 80 (1999) 211-229] to construct analytical upper bounds on the distance to stationarity. These lead to upper bounds on the amount of burn-in that is required to get the chain within a prespecified (total variation) distance of the stationary distribution. The results are illustrated with a numerical example.

</details>

<details>

<summary>2004-06-23 12:39:49 - Training samples in objective Bayesian model selection</summary>

- *James O. Berger, Luis R. Pericchi*

- `0406460v1` - [abs](http://arxiv.org/abs/0406460v1) - [pdf](http://arxiv.org/pdf/math/0406460v1)

> Central to several objective approaches to Bayesian model selection is the use of training samples (subsets of the data), so as to allow utilization of improper objective priors. The most common prescription for choosing training samples is to choose them to be as small as possible, subject to yielding proper posteriors; these are called minimal training samples.   When data can vary widely in terms of either information content or impact on the improper priors, use of minimal training samples can be inadequate.   Important examples include certain cases of discrete data, the presence of censored observations, and certain situations involving linear models and explanatory variables. Such situations require more sophisticated methods of choosing training samples. A variety of such methods are developed in this paper, and successfully applied in challenging situations.

</details>

<details>

<summary>2004-06-23 12:41:22 - Optimal predictive model selection</summary>

- *Maria Maddalena Barbieri, James O. Berger*

- `0406464v1` - [abs](http://arxiv.org/abs/0406464v1) - [pdf](http://arxiv.org/pdf/math/0406464v1)

> Often the goal of model selection is to choose a model for future prediction, and it is natural to measure the accuracy of a future prediction by squared error loss. Under the Bayesian approach, it is commonly perceived that the optimal predictive model is the model with highest posterior probability, but this is not necessarily the case. In this paper we show that, for selection among normal linear models, the optimal predictive model is often the median probability model, which is defined as the model consisting of those variables which have overall posterior probability greater than or equal to 1/2 of being in a model. The median probability model often differs from the highest probability model.

</details>

<details>

<summary>2004-06-25 10:24:19 - A stochastic process approach to false discovery control</summary>

- *Christopher Genovese, Larry Wasserman*

- `0406519v1` - [abs](http://arxiv.org/abs/0406519v1) - [pdf](http://arxiv.org/pdf/math/0406519v1)

> This paper extends the theory of false discovery rates (FDR) pioneered by Benjamini and Hochberg [J. Roy. Statist. Soc. Ser. B 57 (1995) 289-300].   We develop a framework in which the False Discovery Proportion (FDP)--the number of false rejections divided by the number of rejections--is treated as a stochastic process. After obtaining the limiting distribution of the process, we demonstrate the validity of a class of procedures for controlling the False Discovery Rate (the expected FDP). We construct a confidence envelope for the whole FDP process. From these envelopes we derive confidence thresholds, for controlling the quantiles of the distribution of the FDP as well as controlling the number of false discoveries. We also investigate methods for estimating the p-value distribution.

</details>


## 2004-10

<details>

<summary>2004-10-05 08:35:20 - Breakdown points for maximum likelihood estimators of location-scale mixtures</summary>

- *Christian Hennig*

- `0410073v1` - [abs](http://arxiv.org/abs/0410073v1) - [pdf](http://arxiv.org/pdf/math/0410073v1)

> ML-estimation based on mixtures of Normal distributions is a widely used tool for cluster analysis. However, a single outlier can make the parameter estimation of at least one of the mixture components break down. Among others, the estimation of mixtures of t-distributions by McLachlan and   Peel [Finite Mixture Models (2000) Wiley, New York] and the addition of a further mixture component accounting for ``noise'' by Fraley and Raftery   [The Computer J. 41 (1998) 578-588] were suggested as more robust alternatives.   In this paper, the definition of an adequate robustness measure for cluster analysis is discussed and bounds for the breakdown points of the mentioned methods are given. It turns out that the two alternatives, while adding stability in the presence of outliers of moderate size, do not possess a substantially better breakdown behavior than estimation based on Normal mixtures. If the number of clusters s is treated as fixed, r additional points suffice for all three methods to let the parameters of r clusters explode. Only in the case of r=s is this not possible for t-mixtures. The ability to estimate the number of mixture components, for example, by use of the Bayesian information criterion of Schwarz [Ann. Statist. 6 (1978)   461-464], and to isolate gross outliers as clusters of one point, is crucial for an improved breakdown behavior of all three techniques. Furthermore, a mixture of Normals with an improper uniform distribution is proposed to achieve more robustness in the case of a fixed number of components.

</details>

<details>

<summary>2004-10-05 08:57:43 - Asymptotic global robustness in bayesian decision theory</summary>

- *Christophe Abraham, Benoit Cadre*

- `0410074v1` - [abs](http://arxiv.org/abs/0410074v1) - [pdf](http://arxiv.org/pdf/math/0410074v1)

> In Bayesian decision theory, it is known that robustness with respect to the loss and the prior can be improved by adding new observations. In this article we study the rate of robustness improvement with respect to the number of observations n. Three usual measures of posterior global robustness are considered: the (range of the) Bayes actions set derived from a class of loss functions, the maximum regret of using a particular loss when the subjective loss belongs to a given class and the range of the posterior expected loss when the loss function ranges over a class. We show that the rate of convergence of the first measure of robustness is \sqrtn, while it is n for the other measures under reasonable assumptions on the class of loss functions. We begin with the study of two particular cases to illustrate our results.

</details>

<details>

<summary>2004-10-05 09:23:44 - Game theory, maximum entropy, minimum discrepancy and robust Bayesian decision theory</summary>

- *Peter D. Grunwald, A. Philip Dawid*

- `0410076v1` - [abs](http://arxiv.org/abs/0410076v1) - [pdf](http://arxiv.org/pdf/math/0410076v1)

> We describe and develop a close relationship between two problems that have customarily been regarded as distinct: that of maximizing entropy, and that of minimizing worst-case expected loss. Using a formulation grounded in the equilibrium theory of zero-sum games between Decision Maker and   Nature, these two problems are shown to be dual to each other, the solution to each providing that to the other. Although Tops\oe described this connection for the Shannon entropy over 20 years ago, it does not appear to be widely known even in that important special case. We here generalize this theory to apply to arbitrary decision problems and loss functions. We indicate how an appropriate generalized definition of entropy can be associated with such a problem, and we show that, subject to certain regularity conditions, the above-mentioned duality continues to apply in this extended context.   This simultaneously provides a possible rationale for maximizing entropy and a tool for finding robust Bayes acts. We also describe the essential identity between the problem of maximizing entropy and that of minimizing a related discrepancy or divergence between distributions. This leads to an extension, to arbitrary discrepancies, of a well-known minimax theorem for the case of Kullback-Leibler divergence (the ``redundancy-capacity theorem'' of information theory). For the important case of families of distributions having certain mean values specified, we develop simple sufficient conditions and methods for identifying the desired solutions.

</details>

<details>

<summary>2004-10-05 09:52:32 - A Bernstein-von Mises theorem in the nonparametric right-censoring model</summary>

- *Yongdai Kim, Jaeyong Lee*

- `0410083v1` - [abs](http://arxiv.org/abs/0410083v1) - [pdf](http://arxiv.org/pdf/math/0410083v1)

> In the recent Bayesian nonparametric literature, many examples have been reported in which Bayesian estimators and posterior distributions do not achieve the optimal convergence rate, indicating that the Bernstein-von   Mises theorem does not hold. In this article, we give a positive result in this direction by showing that the Bernstein-von Mises theorem holds in survival models for a large class of prior processes neutral to the right. We also show that, for an arbitrarily given convergence rate n^{-\alpha} with 0<\alpha \leq 1/2, a prior process neutral to the right can be chosen so that its posterior distribution achieves the convergence rate n^{-\alpha}.

</details>

<details>

<summary>2004-10-05 11:02:19 - Simultaneous prediction of independent Poisson observables</summary>

- *Fumiyasu Komaki*

- `0410094v1` - [abs](http://arxiv.org/abs/0410094v1) - [pdf](http://arxiv.org/pdf/math/0410094v1)

> Simultaneous predictive distributions for independent Poisson observables are investigated. A class of improper prior distributions for Poisson means is introduced. The Bayesian predictive distributions based on priors from the introduced class are shown to be admissible under the Kullback-Leibler loss. A Bayesian predictive distribution based on a prior in this class dominates the Bayesian predictive distribution based on the Jeffreys prior.

</details>

<details>

<summary>2004-10-11 19:41:55 - Improved Vapnik Cervonenkis bounds</summary>

- *Olivier Catoni*

- `0410280v1` - [abs](http://arxiv.org/abs/0410280v1) - [pdf](http://arxiv.org/pdf/math/0410280v1)

> We give a new proof of VC bounds where we avoid the use of symmetrization and use a shadow sample of arbitrary size. We also improve on the variance term. This results in better constants, as shown on numerical examples. Moreover our bounds still hold for non identically distributed independent random variables. Keywords: Statistical learning theory, PAC-Bayesian theorems, VC dimension.

</details>

<details>

<summary>2004-10-19 18:34:32 - Direct pivotal predictive inference</summary>

- *George Kahrimanis, Daniel Berleant*

- `0410424v1` - [abs](http://arxiv.org/abs/0410424v1) - [pdf](http://arxiv.org/pdf/math/0410424v1)

> Without assuming any pdf for some measured parameter, we derive a predictive pdf for the outcome of a second measurement, given the outcome of the first measurement and two common assumptions about the noise. These are that (1) it is additive, and (2) it is of some known pdf. The argument is based on a Bayesian analysis of the noise when no pdf is provided for the value of the parameter. In this way we avoid assuming an ad-hoc prior. We clarify how this method of direct predictive inference is distinct from fiducial prediction. We specify the distinct flaw in the fiducial argument, and outline the importance of this development in the foundations of probability and statistics.   Keywords: nonparametric predictive inference, direct pivotal argument, pivotal argument, fiducial argument, fiducial prediction, Bayesian inference, reference prior, reference class.

</details>


## 2004-11

<details>

<summary>2004-11-23 16:39:07 - Fast Non-Parametric Bayesian Inference on Infinite Trees</summary>

- *Marcus Hutter*

- `0411515v1` - [abs](http://arxiv.org/abs/0411515v1) - [pdf](http://arxiv.org/pdf/math/0411515v1)

> Given i.i.d. data from an unknown distribution, we consider the problem of predicting future items. An adaptive way to estimate the probability density is to recursively subdivide the domain to an appropriate data-dependent granularity. A Bayesian would assign a data-independent prior probability to "subdivide", which leads to a prior over infinite(ly many) trees. We derive an exact, fast, and simple inference algorithm for such a prior, for the data evidence, the predictive distribution, the effective model dimension, and other quantities.

</details>


## 2004-12

<details>

<summary>2004-12-28 15:21:37 - Bayes Theorem and the cMPE-Method: Differences, Complementarities and the Importance of Discerning between Weight-bearing and Extensional Evidence</summary>

- *R. Gottlob*

- `0406090v2` - [abs](http://arxiv.org/abs/0406090v2) - [pdf](http://arxiv.org/pdf/math/0406090v2)

> Both, Bayes Theorem and the cMPE-Method serve for establishing relations between systems of probabilities. By the cMPE-Method non-conditional probabilities are added, by the DPE-Method, they are subtracted, however, in both versions allowing for the non-linearity of non-disjunctive probabilities. Semantic independence is prerequisite. As compared with the results of semantically homogeneous series of observations, the variety of evidence permits arrival at higher probabilities. The advantage of the Bayesian method lies in allowing for evidence extraneous to the domain covered by the hypothesis. We must differentiate between extensional and weight-bearing evidence. Operations based on purely weight-bearing evidence (cMPE-Method) neglect the extensional evidence and some operations according to Bayes Theorem may neglect weight-bearing evidence at least partially. These and some other shortcomings may be remedied by operations, combining both of the approaches.

</details>

